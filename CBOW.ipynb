{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a1776e7-4baf-4f20-bcfb-2a6e29de17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 导入所需的库：PyTorch核心、神经网络模块、优化器、NumPy和Counter\n",
    "\n",
    "text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules called a program.\n",
    "People create programs to direct processes.\"\"\"\n",
    "\n",
    "# 定义一个简单的文本作为训练数据\n",
    "\n",
    "words = text.split()\n",
    "# 将文本分割成单词列表\n",
    "\n",
    "vocab = set(words)\n",
    "# 创建词汇表（去重）\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "# 创建单词到索引的映射字典\n",
    "\n",
    "ix_to_word = [word for word, i in word_to_ix.items()]\n",
    "# 创建索引到单词的映射字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a36baf6c-79d2-4d31-8ded-4270e6a2ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['things', 'called', 'by', 'direct', 'As', 'computational', 'The', 'inhabit', 'that', 'beings']\n",
      "[{'things': 0}, {'called': 1}, {'by': 2}, {'direct': 3}, {'As': 4}, {'computational': 5}, {'The': 6}, {'inhabit': 7}, {'that': 8}, {'beings': 9}]\n",
      "['things', 'called', 'by', 'direct', 'As', 'computational', 'The', 'inhabit', 'that', 'beings']\n"
     ]
    }
   ],
   "source": [
    "print([element for idx, element in enumerate(vocab) if idx < 10])\n",
    "print([{element: idx} for idx, element in enumerate(word_to_ix) if idx <10])\n",
    "print(ix_to_word[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f9f435d-f2d0-4148-b0f5-63c7b83abd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # 创建词嵌入层\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        # 创建线性层，用于将嵌入映射回词汇表大小\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).mean(dim=0)\n",
    "        # 获取输入单词的嵌入并计算平均值\n",
    "        out = self.linear(embeds)\n",
    "        # 通过线性层传递嵌入\n",
    "        log_probs = nn.functional.log_softmax(out, dim=0)\n",
    "        # 应用log softmax函数获取对数概率\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bacea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cbow_dataset(words, context_size=2):\n",
    "    data = []\n",
    "    for i in range(context_size, len(words) - context_size):\n",
    "        context = [words[i-2], words[i-1], words[i+1], words[i+2]]\n",
    "        # 获取目标词的上下文（前后各两个词）\n",
    "        target = words[i]\n",
    "        # 获取目标词\n",
    "        data.append((context, target))\n",
    "    return data\n",
    "    # 返回(上下文, 目标词)对的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f06b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cbow(model, data, word_to_ix, learning_rate=0.1, num_epochs=100):\n",
    "    loss_function = nn.NLLLoss()\n",
    "    # 定义负对数似然损失函数\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # 定义随机梯度下降优化器\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for context, target in data:\n",
    "            context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "            # 将上下文单词转换为索引张量\n",
    "            model.zero_grad()\n",
    "            # 清除之前的梯度\n",
    "            log_probs = model(context_idxs)\n",
    "            # 前向传播\n",
    "            loss = loss_function(log_probs.unsqueeze(0), torch.tensor([word_to_ix[target]]))\n",
    "            # 计算损失\n",
    "            loss.backward()\n",
    "            # 反向传播\n",
    "            optimizer.step()\n",
    "            # 更新模型参数\n",
    "            total_loss += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss}')\n",
    "            # 每10个epoch打印一次损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca0dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 174.11824560165405\n",
      "Epoch 10, Loss: 92.34939754009247\n",
      "Epoch 20, Loss: 45.422476068139076\n",
      "Epoch 30, Loss: 22.1721078902483\n",
      "Epoch 40, Loss: 12.155173022300005\n",
      "Epoch 50, Loss: 7.560733236372471\n",
      "Epoch 60, Loss: 5.208675600588322\n",
      "Epoch 70, Loss: 3.8647050466388464\n",
      "Epoch 80, Loss: 3.0234724394977093\n",
      "Epoch 90, Loss: 2.4582118475809693\n",
      "Context: ['We', 'are', 'to', 'study']\n",
      "Predicted word: about\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    CONTEXT_SIZE = 2\n",
    "    EMBEDDING_DIM = 10\n",
    "    \n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    cbow_dataset = create_cbow_dataset(words, CONTEXT_SIZE)\n",
    "    # 创建CBOW数据集\n",
    "    model = CBOW(vocab_size, EMBEDDING_DIM)\n",
    "    # 初始化CBOW模型\n",
    "    \n",
    "    train_cbow(model, cbow_dataset, word_to_ix)\n",
    "    # 训练模型\n",
    "    \n",
    "    context = ['We', 'are', 'to', 'study']\n",
    "    context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "    # 准备测试上下文\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        log_probs = model(context_idxs)\n",
    "    # 使用训练好的模型进行预测\n",
    "    \n",
    "    predicted_word_idx = torch.argmax(log_probs).item()\n",
    "    predicted_word = ix_to_word[predicted_word_idx]\n",
    "    # 获取预测的单词\n",
    "    \n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"Predicted word: {predicted_word}\")\n",
    "    # 打印结果\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # 如果直接运行此脚本，执行main函数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
